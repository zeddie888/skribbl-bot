{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_warmup.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeddie888/skribbl-bot/blob/main/pytorch_warmup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QA1D6eIszX_"
      },
      "source": [
        "This notebook will help you get familiar with Google Colab, and walk you through modifying a simple model with PyTorch and training it on the [MNIST dataset](http://yann.lecun.com/exdb/mnist/)\n",
        "\n",
        "To enable GPU:\n",
        "\n",
        "Edit -> Notebook settings -> Hardware accelerator -> GPU -> Save\n",
        "\n",
        "If you see an error about enabling third-party cookies check any ad-blockers you may be running and [enable third-party cookies on your browser](https://research.google.com/colaboratory/faq.html#third-party-cookies)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oINm7sOOdpaL"
      },
      "source": [
        "# Download and install pytorch\n",
        "# If you see \"CUDA enabled: false\" make sure you set the hardware accelerator for the notebook to GPU\n",
        "from os import path\n",
        "\n",
        "!pip install torch torchvision\n",
        "  \n",
        "import torch\n",
        "print('Version', torch.__version__)\n",
        "print('CUDA enabled:', torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnhVUth9X1Cp"
      },
      "source": [
        "The following section implements a simple model along with the train and test functions. Even with a single convolutional layer, two fully connected layers, and a tanh activation function you will see the accuracy is pretty high. Experiment with modifying different parts of the model to see how high you can get the accuracy to be. Specifically look into: \n",
        "\n",
        "*   Adding more [convolutional](https://pytorch.org/docs/stable/nn.html#convolution-layers) and [linear](https://pytorch.org/docs/stable/nn.html#linear-layers) layers\n",
        "*   Adding a [pooling](https://pytorch.org/docs/stable/nn.html#convolution-layers) layer after the convolutional layer\n",
        "*   Changing the [activation](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity) layers in the forward pass\n",
        "*   Adding [dropout](https://pytorch.org/docs/stable/nn.html#dropout-layers) layers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oKKR9EsoK9G"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Create a PyTorch module to implement the model\n",
        "class MNISTNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNISTNet, self).__init__()\n",
        "        \n",
        "        # Model layers\n",
        "        # Keep in mind the MNIST dataset provides grayscale images (1 channel) of 28 x 28 dimensions\n",
        "        self.conv1 = nn.Conv2d(1, 3, 3)\n",
        "        self.fc1 = nn.Linear(26 * 26 * 3, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass, this defines how the data actually passes through your network\n",
        "        x = torch.tanh(self.conv1(x))\n",
        "        x = x.view(-1, 26 * 26 * 3)\n",
        "        x = torch.tanh(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def loss(self, prediction, label, reduction='mean'):\n",
        "        return F.cross_entropy(prediction, label, reduction = reduction)\n",
        "\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch, log_interval):\n",
        "    model.train()\n",
        "    for batch_idx, (data, label) in enumerate(train_loader):\n",
        "        data, label = data.to(device), label.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(data)\n",
        "        loss = model.loss(output, label, 'mean')\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, label in test_loader:\n",
        "            data, label = data.to(device), label.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += model.loss(output, label).item()\n",
        "            pred = output.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(label.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RGqJ4L9mDjK"
      },
      "source": [
        "On top of modifying your model, also try changing these hyperparameters to set how quickly the model will learn and how much data it should train on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNf3AoHVvKXI"
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "TEST_BATCH_SIZE = 1000\n",
        "EPOCHS = 5\n",
        "\n",
        "LEARNING_RATE = 0.01\n",
        "MOMENTUM = 0.5\n",
        "\n",
        "USE_CUDA = True\n",
        "SEED = 0 # Sets a seed for generating random numbers\n",
        "LOG_INTERVAL = 100 # How often training results should be printed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50zDbqjXu_Qq"
      },
      "source": [
        "use_cuda = USE_CUDA and torch.cuda.is_available()\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print('Using device', device)\n",
        "import multiprocessing\n",
        "print('num cpus:', multiprocessing.cpu_count())\n",
        "\n",
        "kwargs = {'num_workers': multiprocessing.cpu_count(),\n",
        "          'pin_memory': True} if use_cuda else {}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=TEST_BATCH_SIZE, **kwargs)\n",
        "\n",
        "\n",
        "model = MNISTNet().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
        "\n",
        "try:\n",
        "    for epoch in range(0, EPOCHS + 1):\n",
        "        train(model, device, train_loader, optimizer, epoch, LOG_INTERVAL)\n",
        "        test(model, device, test_loader)\n",
        "except KeyboardInterrupt as ke:\n",
        "    print('Interrupted')\n",
        "except:\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeZZX1lKlIXy"
      },
      "source": [
        "Run the following code block to grab a random image from the test dataset and see the prediction your trained model makes. Try running the code block multiple times to see what unique images your model might make mistakes on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "9G7nPAgTV7s0",
        "outputId": "5c8d49d0-a92d-4aef-97c7-2ee5de205c2a"
      },
      "source": [
        "import random\n",
        "\n",
        "test_image = train_loader.dataset[random.randrange(2000)][0]\n",
        "display(transforms.ToPILImage()(transforms.Resize(100)(test_image)))\n",
        "\n",
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  out = model((test_image[None,...]).to(device))\n",
        "  pred = out.max(1, keepdim=True)[1]\n",
        "  print(\"Prediction: \" + str(pred[0][0].item()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=100x100 at 0x7F077847DAD0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Prediction: 0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}